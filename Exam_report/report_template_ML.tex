\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{color}
\usepackage[pdftex]{graphicx}
\usepackage[svgnames]{xcolor}
\usepackage{array}
\usepackage{parskip}
\usepackage[margin=1in]{geometry}
\usepackage[T1]{fontenc}
\usepackage[many]{tcolorbox}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{appendix}
\usepackage{fancyhdr}
\usepackage{titling}
\usepackage{authblk}

\usepackage{minted} % Pacchetto per evidenziare la sintassi
\usepackage{tcolorbox} % Per riquadri personalizzabili

\usepackage{pgfplots}
\pgfplotsset{compat=1.18} % o una versione compatibile con la tua TeX

\usepackage{caption}

% Configurazione globale per minted: riquadro, numeri di riga, font più piccolo e spezzatura aggressiva
\setminted{
	frame=single,
	linenos,
	fontsize=\footnotesize, % o \scriptsize se vuoi ancora più margine
	breaklines,
	breakanywhere,
	numbersep=4pt,      % distanza tra numeri di riga e codice
	xleftmargin=6pt,    % margine sinistro interno al frame
	framesep=2pt        % distanza testo-bordo
}

\usepackage{csquotes} % consigliato con biblatex
\usepackage{biblatex}
\addbibresource{riferimenti.bib}

\title{\color{FireBrick}\bf{Realizzazione di una applicazione OCR per manoscritti italiani mediante Kraken}}
\author[1]{\color{FireBrick}\bf{Francesco Rombaldoni}}
\affil[1]{f.rombaldoni@campus.uniurb.it}

\date{}

\begin{document}
	\fancypagestyle{firstpage}
	{
		\fancyhead[L]{\footnotesize{\bf{Universit\`a degli Studi di Urbino Carlo Bo}}}
		\fancyhead[R]{\footnotesize{\bf{CdL Magistrale Informatica e Innovazione Digitale}}}
	}
	\thispagestyle{firstpage}
	
	\pagestyle{fancy}
	
	\fancyhead{} % clear all header fields
	\fancyhead[L]{\color{Black}{\footnotesize{\thetitle}}}
	\fancyfoot{} % clear all footer fields
	\fancyfoot[R]{\footnotesize{\bf{\thepage}}}
	\fancyfoot[L]{\footnotesize{\bf{Progetto corso Machine Learning}}}
	
	
	
	\twocolumn
	%------------------------------------------                                       
	%                      Title
	%------------------------------------------
	[{
		\maketitle
		\thispagestyle{firstpage}
		\title{\color{Black}\bf{Realizzazione di una applicazione OCR per manoscritti italiani mediante Kraken}}
		%------------------------------------------                                                           
		%                   Abstract
		%------------------------------------------
		\normalsize
		\begin{tcolorbox}[  colback = WhiteSmoke,
			,
			width=\linewidth,
			arc=1mm, auto outer arc,
			]
			\section*{Riassunto}
			
			Il lavoro svolto per l'esame consiste nel \emph{fine tuning} di un modello pre‑esistente di Kraken, con l'obiettivo di ottenere un sistema in grado di leggere manoscritti in lingua italiana. Nel contesto in cui lavoro (pubblica amministrazione) esiste infatti una forte necessit\`a di strumenti OCR avanzati per la digitalizzazione di documenti storici che, a causa delle normative sulla privacy, dovranno essere distrutti dopo la scadenza dei tempi di conservazione.
			
			Per raggiungere questo obiettivo sono stati scelti alcuni documenti di cui si possedevano gi\`a le trascrizioni. Le pagine sono state scannerizzate, pre‑elaborate con strumenti standard (in particolare ScanTailor) e quindi utilizzate per generare il \emph{ground truth} necessario all'addestramento. I dati cos\`i ottenuti sono stati organizzati e normalizzati mediante una serie di script in Python, sviluppati appositamente per l'utilizzo con Kraken.
			
			Il risultato di questo processo \`e un modello specializzato per la calligrafia italiana adottata nei documenti di riferimento, che raggiunge un'accuratezza media di circa l'88\% a livello di parola su pagine simili a quelle di addestramento (con una deviazione standard di circa 2 punti percentuali). Sebbene il modello non sia ancora sufficientemente affidabile per un utilizzo completamente automatico sulla documentazione clinica, esso costituisce una prova di concetto concreta e gi\`a utile per motivare la richiesta di risorse aggiuntive a livello di comparto, in vista dello sviluppo di uno strumento OCR conforme alle esigenze normative e organizzative dell'INRCA.
		\end{tcolorbox}
		\vspace{1.5ex}
	}]
	
	
	%------------------------------------------
	%                   Main Matter
	%------------------------------------------
	
	\section{Introduzione}
	
	\subsection{Il problema}
	
	Il problema affrontato in questo lavoro nasce dall'esigenza di adeguare la gestione documentale dell'INRCA alle normative vigenti in materia di protezione dei dati personali e conservazione dei documenti, in particolare il Regolamento (UE) 2016/679 (GDPR) e la norma ISO/IEC 21964, che disciplina la transizione dal supporto cartaceo al digitale.
	
	L'INRCA, in quanto istituto sia ospedaliero sia di ricerca, \`e tenuto a garantire il rispetto di tali obblighi, in particolare per quanto riguarda la catalogazione, l'archiviazione e la successiva distruzione dei documenti sensibili. Ci\`o rende necessario disporre di strumenti OCR affidabili, in grado di supportare la digitalizzazione massiva di documenti storici, spesso contenenti anche parti manoscritte.
	
	Una prima analisi ha preso in considerazione alcuni software commerciali largamente diffusi:
	\begin{itemize}
		\item Wondershare PDFelement;
		\item ABBYY FineReader PDF 16;
		\item Nanonets;
		\item Adobe Acrobat.
	\end{itemize}
	
	Tali strumenti sono stati tuttavia scartati in quanto inadeguati al caso d'uso specifico. In particolare, nessuno di essi offre un supporto realmente efficace per documenti contenenti porzioni manoscritte, come ricette mediche o note su pazienti, che costituiscono una parte rilevante della documentazione sanitaria.
	
	In linea teorica, gli OCR basati su tecnologie di intelligenza artificiale sarebbero gli unici in grado di affrontare il carico di lavoro descritto. Tuttavia, la maggior parte delle soluzioni commerciali pi\`u avanzate richiede la trasmissione remota delle pagine da analizzare verso servizi cloud esterni, il che non consente di garantire un controllo completo sulla sicurezza delle informazioni trattate.
	
	Alla luce di queste considerazioni, la necessit\`a \`e quella di disporre di un sistema OCR:
	\begin{itemize}
		\item sufficientemente efficiente da poter essere eseguito interamente in locale;
		\item configurabile e controllabile dagli operatori interni;
		\item adatto a gestire manoscritti in lingua italiana.
	\end{itemize}
	
	Fra le possibili alternative, la scelta \`e ricaduta su Kraken, un OCR open source basato su reti neurali profonde, che consente il \emph{fine tuning} di modelli pre‑esistenti sulla base di dati di addestramento personalizzati. La documentazione ufficiale di Kraken \cite{kraken-site} e il relativo codice sorgente \cite{kraken-github} forniscono una descrizione dell'architettura generale e degli strumenti di addestramento, ma le informazioni risultano piuttosto frammentate: parte del materiale \`e ospitato su repository non pi\`u mantenute e parte su archivi istituzionali europei (ad esempio su Zenodo \cite{kraken-zenodo}), dove alcune pagine storicamente collegate a Kraken non risultano pi\`u disponibili.
	
	\subsection{Input e output}
	
	Gli \emph{input} del sistema sono le scannerizzazioni dei documenti da digitalizzare, sottoposte preventivamente a un processo di pulizia e normalizzazione tramite ScanTailor (correzione della centratura, ritaglio delle parti non informative, adeguamento del contrasto), mantenendo la risoluzione originale di 600 dpi.
	
	Gli \emph{output} considerati in questo lavoro sono file di testo semplice (\texttt{.txt}) contenenti le trascrizioni delle pagine. Ai fini specifici del progetto, non \`e stato ritenuto necessario ottenere un PDF in cui il testo sia selezionabile e sovrapposto all'immagine: l'obiettivo \`e piuttosto quello di creare, per ciascun documento, un ``pacchetto'' costituito dall'immagine scannerizzata e dalla relativa trascrizione.
	
	Questa organizzazione consente di:
	\begin{itemize}
		\item eseguire ricerche testuali sulle trascrizioni per individuare rapidamente i documenti di interesse;
		\item visualizzare, in caso di necessit\`a, l'immagine originale della pagina, preservando l'aspetto grafico del documento.
	\end{itemize}
	
	\subsection{Architettura del modello: CRNN, CTC e LSTM bidirezionali}
	
	Il modello utilizzato da Kraken per il riconoscimento delle righe di testo \`e una
	\emph{Convolutional Recurrent Neural Network} (CRNN) addestrata con una funzione di costo di tipo
	\emph{Connectionist Temporal Classification} (CTC) e dotata di strati ricorrenti LSTM
	(\emph{Long Short‑Term Memory}) bidirezionali.
	
	\paragraph{CRNN: combinazione di convoluzioni e ricorrenza}
	
	Una CRNN combina due idee principali:
	\begin{itemize}
		\item \textbf{Strati convoluzionali (CNN)}: estraggono automaticamente caratteristiche locali
		dall'immagine della riga (contorni, tratti di penna, forme di lettere, ecc.). A differenza
		di metodi basati su feature ingegnerizzate a mano, la CNN impara direttamente dal dato
		quali pattern visivi sono utili per discriminare i caratteri.
		\item \textbf{Strati ricorrenti}: modellano la dipendenza sequenziale lungo la riga.
		Dopo le convoluzioni, l'immagine viene ``compressa'' in una sequenza di vettori di feature
		(uno per ciascuna posizione orizzontale). Gli strati ricorrenti elaborano questa sequenza
		tenendo conto del contesto a sinistra e a destra.
	\end{itemize}
	
	In pratica, l'immagine di una riga viene prima ridotta e trasformata da una CNN in una sequenza
	$\{ \mathbf{f}_1, \mathbf{f}_2, \dots, \mathbf{f}_T \}$, dove ogni $\mathbf{f}_t$ \`e un vettore
	di feature che riassume le informazioni visive di una ``finestra'' verticale della riga. Questa
	sequenza di feature viene poi passata a una rete ricorrente che produce, per ogni passo temporale
	$t$, una rappresentazione arricchita dal contesto.
	
	\paragraph{LSTM bidirezionali}
	
	Per modellare le dipendenze a lungo raggio nella sequenza di feature, Kraken utilizza strati
	ricorrenti di tipo LSTM. Le LSTM sono un'estensione delle RNN
	classiche progettata per evitare il problema del gradiente che svanisce: introducono celle di
	memoria e meccanismi di ``porte'' (input, output, forget) che consentono di mantenere o
	dimenticare informazioni nel tempo in modo controllato.
	
	Nel caso di Kraken le LSTM sono \textbf{bidirezionali}: per ogni posizione $t$ della sequenza,
	la rete calcola due stati:
	\begin{itemize}
		\item uno in direzione \emph{forward}, che processa la sequenza da sinistra a destra;
		\item uno in direzione \emph{backward}, che processa la sequenza da destra a sinistra.
	\end{itemize}
	
	Questi due stati vengono concatenati per ottenere una rappresentazione che tiene conto sia del
	contesto precedente sia di quello successivo rispetto a ciascuna posizione. Questo \`e
	particolarmente utile nel riconoscimento di testo manoscritto, dove l'interpretazione di un
	carattere pu\`o dipendere fortemente dalle lettere adiacenti (ad esempio per distinguere tra
	``m'' e ``rn'').
	
	\paragraph{Funzione di costo CTC (Connectionist Temporal Classification)}
	
	L'uscita della parte ricorrente della rete \`e, per ogni passo temporale $t$, un vettore di
	probabilit\`a sui possibili simboli (lettere, numeri, segni di punteggiatura e un simbolo
	speciale ``blank''). Il problema \`e che:
	\begin{itemize}
		\item non \`e nota a priori la corrispondenza esatta tra posizioni temporali e caratteri
		della trascrizione;
		\item la lunghezza della sequenza di output (numero di passi temporali) \`e di solito diversa
		dalla lunghezza della trascrizione in caratteri.
	\end{itemize}
	
	La funzione di costo \textbf{CTC} \`e stata introdotta proprio per gestire questo tipo di
	situazioni. L'idea di base \`e:
	\begin{itemize}
		\item la rete produce una sequenza di simboli ``estesa'', che pu\`o contenere ripetizioni e
		simboli \emph{blank};
		\item una procedura di \emph{collasso} (\emph{collapse}) elimina i simboli \emph{blank} e
		comprime le ripetizioni consecutive, ottenendo cos\`i una sequenza di caratteri
		``pulita'';
		\item la CTC definisce tutte le possibili sequenze estese che, dopo il collasso, producono
		la trascrizione desiderata, e massimizza la probabilit\`a totale di questo insieme di
		allineamenti.
	\end{itemize}
	
	In altre parole, durante l'addestramento non \`e necessario fornire un allineamento esplicito
	``pixel per carattere'': \`e sufficiente avere, per ogni immagine di riga, la sua
	trascrizione completa. La CTC si occupa di sommare la probabilit\`a di tutti gli allineamenti
	temporalmente compatibili con quella trascrizione.
	
	Formalmente, se indichiamo con $\mathbf{y}_t$ la distribuzione di probabilit\`a sui simboli al
	tempo $t$ e con $\ell$ la sequenza di caratteri corretta, la CTC definisce:
	\[
	\mathcal{L}_{\text{CTC}} = - \log P(\ell \mid \mathbf{y}_1, \dots, \mathbf{y}_T)
	\]
	dove $P(\ell \mid \mathbf{y}_{1:T})$ \`e la somma delle probabilit\`a di tutte le sequenze
	estese che collassano in $\ell$. Il calcolo di questa probabilit\`a avviene tramite un algoritmo
	di tipo \emph{forward--backward}, simile a quello utilizzato nei modelli di Markov nascosti.
	
	\paragraph{Decodifica della sequenza testuale}
	
	In fase di inferenza, dato un output probabilistico per ogni passo temporale, si pu\`o applicare
	una decodifica CTC semplice (ad esempio prendendo ad ogni passo il simbolo con probabilit\`a
	massima e poi collassando ripetizioni e \emph{blank}) oppure metodi pi\`u sofisticati basati su
	\emph{beam search} e, se disponibile, modelli linguistici di supporto.
	
	Nel caso considerato, Kraken utilizza la decodifica CTC per ricostruire la sequenza testuale
	a partire dalle distribuzioni di probabilit\`a prodotte dal modello CRNN. Questo approccio
	consente di addestrare il modello direttamente su coppie immagine–trascrizione senza richiedere
	un allineamento manuale carattere–pixel, ed \`e particolarmente adatto al riconoscimento di
	testo manoscritto, dove la segmentazione esplicita dei singoli caratteri \`e spesso ambigua
	o poco affidabile.
	
	\subsection{Il modello}
	
	Per l'addestramento \`e stato utilizzato come punto di partenza il modello
	\texttt{Tridis\_Medieval\_EarlyModern.mlmodel}, ottenuto tramite il gestore dei modelli incluso
	in Kraken. La documentazione (oggi parzialmente reperibile solo tramite riferimenti indiretti,
	ad esempio su archivi come Zenodo \cite{kraken-zenodo}) suggerisce che questo modello, addestrato
	su manoscritti latini tardo‑medievali e di et\`a moderna, costituisca una buona base di partenza
	per il riconoscimento di grafie storiche europee. L'informazione secondo cui tale modello sarebbe
	adatto anche come base per manoscritti italiani deriva in parte da risposte fornite da strumenti
	di intelligenza artificiale, che a loro volta facevano riferimento a lavori ospitati su repository
	Zenodo non pi\`u direttamente accessibili.
	
	La scelta di questo modello di partenza \`e motivata dalla somiglianza geometrica e stilistica tra
	la grafia dei manoscritti latini pi\`u recenti e quella dei manoscritti italiani novecenteschi
	presenti nel contesto di interesse. L'ipotesi di lavoro \`e che un modello gi\`a addestrato su una
	grande variet\`a di manoscritti latini possa costituire una buona base per un \emph{fine tuning}
	mirato sui manoscritti italiani, richiedendo quindi un numero relativamente contenuto di pagine
	annotate manualmente.
	
	\section{Metodi}
	
	Il processo di addestramento ha seguito una metodologia articolata in pi\`u fasi, resa pi\`u complessa dal fatto che Kraken, originariamente nato come progetto open source, \`e stato successivamente integrato in iniziative istituzionali europee. Nel tempo, parte della documentazione \`e stata spostata o resa meno facilmente accessibile, e molte delle guide online puntano oggi a repository non pi\`u mantenute o a pagine che restituiscono errori 404. La documentazione ufficiale disponibile sul sito del progetto \cite{kraken-site} e sul repository GitHub \cite{kraken-github} fornisce quindi solo una parte del quadro complessivo.
	
	Per orientarmi in questo scenario frammentato ho fatto ampio uso di strumenti di supporto (tra cui GitHub Copilot, reso disponibile dal progetto scolastico di GitHub), al fine di ricostruire una pipeline di addestramento completa e riproducibile.
	
	Dal punto di vista operativo, disponendo di una scheda grafica NVIDIA, ho scelto come sistema operativo Pop\!\_OS, in quanto offre un supporto immediato ai driver proprietari NVIDIA e all'uso dei CUDA core (nel mio caso versione 12). Seguendo le indicazioni raccolte, ho creato un ambiente \texttt{conda} dedicato e installato Kraken tramite \texttt{pip}, insieme alle dipendenze necessarie.
	
	Tutta la logica di preparazione dei dati e gestione dei file di \emph{ground truth} \`e stata implementata in Python, con l'obiettivo di ottenere uno strato di astrazione relativamente semplice da riutilizzare in contesti simili.
	
	\subsection{Gestione delle immagini}
	
	Come base di addestramento sono stati utilizzati circa 150 fogli di documenti, redatti a mano e gi\`a trascritti in precedenza. I fogli sono stati scannerizzati utilizzando una stampante da ufficio professionale con risoluzione di 600 dpi.
	
	Le immagini ottenute sono state quindi pre‑elaborate con il software open source ScanTailor, utilizzando principalmente le impostazioni standard. In questa fase sono stati corretti:
	\begin{itemize}
		\item la centratura delle pagine;
		\item il ritaglio dei margini non informativi;
		\item il bilanciamento complessivo del contenuto visivo, mantenendo la risoluzione a 600 dpi.
	\end{itemize}
	
	Successivamente, ogni pagina \`e stata suddivisa in singole righe di testo. A ciascuna riga \`e stata associata la relativa trascrizione manuale, in modo da costruire un dataset di coppie immagine–testo utilizzabile per il \emph{fine tuning}. La struttura dei file \`e stata organizzata in cartelle dedicate per le immagini e per i testi, con convenzioni di denominazione coerenti per facilitare gli abbinamenti automatici.
	
	\subsection{Il processo di addestramento}
	
	\paragraph{Generazione del \emph{ground truth} dai file \texttt{.md} riga per riga}
	
	Le trascrizioni manuali erano conservate in formato Markdown, scelta che rendeva pi\`u agevole la lettura umana ma richiedeva una fase di pulizia prima di poter essere utilizzate come \emph{ground truth}. Per questo \`e stato sviluppato uno script Python che, dato un insieme di immagini e i corrispondenti file \texttt{.md}, genera un file \texttt{ground\_truth.txt} nel formato atteso da \texttt{ketos} (lo strumento di training associato a Kraken) per l'addestramento.
	
	\paragraph{Normalizzazione del \emph{ground truth} e creazione di \emph{splits} e charset}
	
	Una volta generato il file di \emph{ground truth}, si procede alla sua validazione e normalizzazione, nonch\'e alla creazione degli insiemi di training, validation e test e del relativo insieme di caratteri (\emph{charset}) effettivamente presenti nei dati. Il passo successivo consiste nel suddividere i dati normalizzati in insiemi di training, validation e test e nell'estrarre il charset effettivamente utilizzato.
	
	Come verifica finale di questa fase, \`e stato controllato che il file prodotto fosse coerente con le attese.
	
	\paragraph{Filtraggio delle immagini per la lettura con \texttt{ketos}}
	
	Per facilitare la lettura delle immagini da parte di \texttt{ketos}, le immagini delle righe sono state ulteriormente normalizzate con \texttt{ImageMagick}. Una volta ottenute le immagini nel formato desiderato, i percorsi all'interno dei file di \emph{ground truth} sono stati aggiornati.
	
	\paragraph{Mappatura delle immagini}
	
	Per comodit\`a, sono stati poi estratti i soli percorsi delle immagini, da utilizzare come input diretto per \texttt{ketos}.
	
	\paragraph{Creazione dei file \emph{sidecar} compatibili con \texttt{ketos}}
	
	Poich\'e le versioni pi\`u recenti di Kraken delegano a \texttt{ketos} la gestione del training, \`e stato necessario generare, per ogni immagine, un file \texttt{.gt.txt} contenente la trascrizione corrispondente.
	
	\section{Risultati sperimentali}
	
	In questa sezione vengono riportati i risultati ottenuti dal modello fine‑tuned in diversi scenari di test, con l'obiettivo di valutare sia la capacit\`a del modello di adattarsi alla specifica calligrafia su cui \`e stato addestrato, sia il suo grado di generalizzazione a scritture differenti.
	
	\subsection{Metrica utilizzata}
	
	Dato che il modello opera riga per riga producendo sequenze di caratteri, la valutazione naturale sarebbe basata su indicatori quali il \emph{Character Error Rate} (CER) o il \emph{Word Error Rate} (WER). Nel presente progetto, tuttavia, la metrica pi\`u rilevante per l'utente finale (l'operatore che utilizza le trascrizioni per la ricerca documentale e per adempiere agli obblighi normativi) \`e la correttezza delle singole parole.
	
	Per questo motivo si considera la seguente metrica intuitiva:
	
	{
		\footnotesize
	\[
	\text{Accuratezza parole} =
	\frac{\text{\# parole riconosciute correttamente}}{\text{\# parole totali}}.
	\]
	}
	
	
	In tutti gli esperimenti ogni prova consiste nel sottoporre al modello un foglio contenente 100 parole manoscritte, e nel contare quante di esse vengono riconosciute correttamente. I valori riportati di seguito sono calcolati su 20 prove indipendenti per ciascuno scenario e vengono sintetizzati tramite media e deviazione standard.
	
	Si segnala inoltre che i test condotti hanno permesso di riutilizzare parte dei documenti di verifica, poich\'e nella fase di test \`e stata disabilitata l'opzione di usare parte del campione riconosciuto come ulteriore materiale di addestramento.
	
	\subsection{Scenario 1: pagine usate in addestramento}
	
	Nel primo scenario il modello \`e stato testato su pagine appartenenti agli stessi documenti utilizzati per il training, quindi:
	\begin{itemize}
		\item stessa persona che ha scritto a mano tutte le pagine;
		\item stessa tipologia di carta e impaginazione;
		\item condizioni di scansione controllate (600 dpi e pre‑elaborazione con ScanTailor).
	\end{itemize}
	
	Sono state condotte 20 prove indipendenti. In ciascuna prova il modello ha riconosciuto un foglio contenente 100 parole, e per ogni foglio \`e stato contato il numero di parole trascritte correttamente. La media sulle 20 prove risulta pari a:
	\[
	\text{Accuratezza media} \approx 88\% \pm 2\%,
	\]
	dove $\pm 2\%$ rappresenta approssimativamente la deviazione standard tra le prove (cio\`e, nella maggior parte dei casi, l'accuratezza per singolo foglio ricade nell'intervallo 86–90\%).
	
	Gli errori non comportano quasi mai uno stravolgimento completo della parola, ma consistono piuttosto in sostituzioni di singole lettere graficamente simili (ad esempio \emph{``casa''} riconosciuta come \emph{``caso''}). Questi risultati indicano che il \emph{fine tuning} ha effettivamente permesso al modello di apprendere in maniera soddisfacente la calligrafia specifica dell'autore dei documenti.
	
	\subsection{Scenario 2: altra persona, stessa tipologia di fogli}
	
	Nel secondo scenario l'OCR \`e stato applicato a pagine manoscritte da una persona diversa, ma su fogli con caratteristiche simili (righe prestampate, impaginazione analoga a quella dei documenti usati in addestramento).
	
	Anche in questo caso sono state condotte 20 prove indipendenti, ciascuna su un foglio contenente 100 parole. La media sulle 20 prove risulta pari a:
	\[
	\text{Accuratezza media} \approx 61\% \pm 2\%,
	\]
	cio\`e il modello riconosce correttamente in media 61 parole su 100, con una variabilit\`a tra le prove di circa due punti percentuali.
	
	L'output rimane comunque leggibile e utile come bozza iniziale, ma la quantit\`a di correzioni manuali richieste aumenta sensibilmente. Questa diminuzione di prestazioni mette in luce un aspetto atteso: con un dataset di addestramento relativamente limitato (circa 150 pagine), il modello tende a specializzarsi sulla calligrafia di riferimento e fatica a generalizzare a scritture diverse, pur mantenendo una certa capacit\`a di riconoscere la struttura delle parole.
	
	\subsection{Ruolo della qualit\`a di scansione}
	
	Durante i test \`e emerso che una parte consistente delle difficolt\`a non \`e dovuta soltanto alla calligrafia, ma anche alla qualit\`a della scansione. Pagine acquisite con inclinazione eccessiva, contrasto basso o sfocatura locale risultano notevolmente pi\`u difficili da riconoscere, indipendentemente dal contenuto testuale.
	
	Ci\`o suggerisce che, oltre al miglioramento del modello, un elemento cruciale per aumentare l'accuratezza complessiva \`e il controllo del processo di acquisizione (scelta dello scanner, impostazioni stabili, eventuale normalizzazione delle immagini prima del riconoscimento).
	
	\subsection{Sintesi dei risultati}
	
	La Tabella~\ref{tab:accuracy_scenari} riassume i risultati principali:
	
	\begin{center}
		\resizebox{\columnwidth}{!}{%
			\begin{tabular}{@{}l c@{}}
				\hline
				Scenario di test & Accuratezza parole (media \(\pm\) dev. std.) \\
				\hline
				Stessa persona (pagine dei documenti di riferimento) & \(88\% \pm 2\%\) \\
				Altra persona, stessa tipologia di fogli            & \(61\% \pm 2\%\) \\
				\hline
			\end{tabular}%
		}
		\captionof{table}{Accuratezza a livello di parola in due scenari di test, calcolata su 20 prove indipendenti per scenario. Ogni prova prevede il riconoscimento di un foglio contenente 100 parole.}
		\label{tab:accuracy_scenari}
	\end{center}
	
	\begin{figure}[h]
		\centering
		\begin{tikzpicture}
			\begin{axis}[
				ybar,
				ymin=0,ymax=100,
				bar width=18pt,
				enlarge x limits=0.35,
				ylabel={Accuratezza parole (\%)},
				symbolic x coords={Stessa persona,Altra persona},
				xtick=data,
				nodes near coords,
				nodes near coords align={vertical},
				width=0.9\columnwidth,
				height=0.55\textheight,
				ylabel style={font=\small},
				tick label style={font=\small},
				]
				\addplot coordinates {
					(Stessa persona, 88)
					(Altra persona, 61)
				};
			\end{axis}
		\end{tikzpicture}
		\caption{Accuratezza media a livello di parola nei due scenari di test considerati (20 prove da 100 parole ciascuna per scenario).}
		\label{fig:accuracy_bar}
	\end{figure}
	
	Dal punto di vista applicativo, questi risultati mostrano che il modello fine‑tuned, pur non essendo ancora utilizzabile in modo completamente automatico, \`e gi\`a in grado di ridurre in misura significativa il carico di trascrizione manuale per la calligrafia su cui \`e stato addestrato. Inoltre, i test su una seconda persona confermano che, con un aumento del numero di pagine annotate e un maggiore controllo sulla qualit\`a di scansione, \`e realistico puntare a livelli di accuratezza pi\`u elevati anche per popolazioni di scriventi pi\`u ampie.
	
	\begin{figure}[h]
		\centering
		\begin{tikzpicture}
			\begin{axis}[
				xlabel={Numero di pagine annotate per il training},
				ylabel={Accuratezza parole (\%)},
				xmin=0, xmax=1050,
				ymin=60, ymax=100,
				xtick={0,50,100,150,300,1000},
				ytick={60,70,80,90,100},
				width=0.9\columnwidth,
				height=0.55\textheight,
				grid=both,
				grid style={gray!20},
				tick label style={font=\small},
				xlabel style={font=\small},
				ylabel style={font=\small},
				]
				\addplot[
				color=FireBrick,
				mark=*,
				thick
				] coordinates {
					(50, 75)
					(100, 83)
					(150, 88)
					(300, 92)
					(1000, 95)
				};
			\end{axis}
		\end{tikzpicture}
		\caption{Andamento qualitativo atteso dell'accuratezza a livello di parola al crescere del numero di pagine annotate utilizzate per il training. Il punto a 150 pagine corrisponde ai risultati effettivamente ottenuti; gli altri valori sono stime indicative.}
		\label{fig:accuracy_vs_pages}
	\end{figure}
	
	\section{Conclusioni}
	
	I risultati ottenuti indicano che il modello fine‑tuned rappresenta una prima base operativa per l'introduzione di un OCR per manoscritti italiani all'interno dell'INRCA. Nel caso della calligrafia specifica utilizzata per l'addestramento, il sistema raggiunge un'accuratezza a livello di parola prossima al 90\%, consentendo di ridurre in modo sensibile il tempo necessario per produrre trascrizioni utilizzabili.
	
	Tuttavia, il modello non \`e ancora sufficientemente robusto da poter essere impiegato in maniera completamente automatica sulla documentazione clinica reale. In particolare:
	\begin{itemize}
		\item la generalizzazione a scritture di persone diverse risulta ancora limitata (circa il 61\% di parole corrette, con una deviazione standard di 2\%);
		\item la qualit\`a della scansione influisce in maniera significativa sui risultati;
		\item permane la necessit\`a di una supervisione umana per la correzione degli errori.
	\end{itemize}
	
	Nonostante questi limiti, il lavoro dimostra la fattibilit\`a tecnica di uno strumento OCR specializzato, eseguibile interamente in locale e potenzialmente integrabile nei flussi documentali dell'istituto. Ci\`o costituisce un elemento importante per motivare la richiesta di fondi dedicati allo sviluppo di una soluzione pi\`u completa e matura.
	
	\subsection{Sviluppi futuri}
	
	Per rendere il sistema sufficientemente affidabile in ambito produttivo saranno necessari ulteriori passaggi:
	
	\begin{itemize}
		\item aumentare significativamente il numero di pagine annotate, passando dalle circa 150 attuali ad almeno un ordine di grandezza superiore (nell'ordine delle mille pagine), in modo da migliorare la capacit\`a di generalizzazione del modello;
		\item coinvolgere il DPO aziendale per definire un protocollo di selezione, anonimizzazione e utilizzo di un campione rappresentativo di documenti clinici reali;
		\item rafforzare la pipeline di acquisizione delle immagini, standardizzando il processo di scansione e le operazioni di pre‑elaborazione;
		\item valutare l'introduzione di un modulo di post‑processing linguistico (ad esempio un correttore contestuale) che possa correggere automaticamente gli errori pi\`u frequenti sulla base del lessico e del contesto.
	\end{itemize}
	
	Il progetto presentato \`e stato giudicato di interesse nazionale dal mio dirigente di comparto, aprendo la possibilit\`a di richiedere risorse dedicate, inclusa eventualmente l'assunzione a tempo determinato di personale con il compito specifico di preparare i dati di addestramento. In questa prospettiva, il lavoro svolto costituisce un primo tassello concreto verso la realizzazione di uno strumento OCR conforme sia alle esigenze operative sia agli obblighi normativi in materia di protezione dei dati e conservazione della documentazione storica.
	
	\printbibliography	
\end{document}